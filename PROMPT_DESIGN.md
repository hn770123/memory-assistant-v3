## アプリケーションの名前
 AI秘書

## UI
 ブラウザ のチャット
 チャットに表示する名前は"アシスタント"と"あなた"

## 技術スタック
 Python  
 LLM(Ollama + llama3.1:8b)  
 MCP(MCP Python SDK)  
 SQLite  

## 概要
 文字入力に応答するアシスタント  
 MCP経由でユーザーの属性、ユーザーの記憶、ユーザーの目標、アシスタントへのお願い を読み込んで答えます  
 入力内容から、ユーザーの属性、ユーザーの目標、その他ユーザーの記憶、アシスタントへのお願い を自動で保存します（含まれない場合は記憶しない）  
 入力内容（直前のAIの回答＋それに対してのユーザーの入力）に記憶すべき内容が含まれているか抽出と判定もLLMを使用してください。AIの回答をユーザーの属性や記憶と認識しないような条件を入れてください。  
 保存処理は直接ＤＢへ書き込む（MCPで実装不要）
 MCP経由で取得する内容（コンテキスト）をなるべく少なくするため（LLMが正しくパラメーターを作成できるように）API設計を工夫する  
 トークン圧縮のため、最後の入力から５分経過するか、"ありがとう"と入力されると、それ以前のメッセージは参照しないようにする（画面には残す）  
 ＤＢの保守画面を作成（参照、変更、削除）  
 テストモードを作成（Ollamaに渡すコンテキストを全て表示するモード）   
 記憶の整理・圧縮機能を備えます。記憶の統合（同じ意味のものを１つに）や整形（表現を整える）、属性/目標のアップデート（矛盾する内容を新しい方で更新）、そして圧縮（表現の簡素化）を行います。長期記憶ほど短く圧縮していく（人間の記憶システムを参考）。記憶の整理・圧縮のステップ１つ１つをリアルタイムで画面に表示する。  

## フロー
 入力テキスト → システムプロンプト + 入力履歴 + テキスト -> Ollama -> MCPで検索 -> 応答 -> 
 （ユーザーが応答を読む時間に）入力テキストの内容をOllamaで解析 → （必要なら）ＤＢに記録  
 Ollamaへ並列してリクエストしない
 
## 実行環境
 3070tiを搭載したWindows11のノートパソコン

## その他要望
 このプロジェクトは私が使用する予定ではありますが、LLMを使ったシステム構築を学ぶたため企画したものです。Pythonも基本構文以上の知識はありません。HTMLやCSSの知識も怪しいです。なので、可能な限り私の学びになるように細かく日本語のコメントを入れて下さい。
